{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import context_changers\n",
    "import ct_model\n",
    "import dmc\n",
    "import drqv2\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task_name = 'reacher_hard' # Name of the task\n",
    "expert_frame_stack = 3  # Size of the frame stack with which the expert was trained\n",
    "action_repeat = 2  # Number of action repeat\n",
    "seed = 3\n",
    "xml_path = 'domain_xmls/reacher.xml'  # XML of the task with some updates\n",
    "episode_len = 100  # Length of the episode\n",
    "context_camera_ids = [0]  # Number of camera\n",
    "learner_camera_id = 0\n",
    "im_w = 64\n",
    "im_h = 64\n",
    "\n",
    "cam_id = random.choice(context_camera_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.set_seed_everywhere(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading of the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expert: drqv2.DrQV2Agent = drqv2.DrQV2Agent.load('experts/reacher_hard.pt')\n",
    "expert.train(training=False)\n",
    "\n",
    "context_translator: ct_model.CTNet = ct_model.CTNet.load('ct/reacher_hard.pt').to(utils.device())\n",
    "context_translator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and wrapping of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expert_env = dmc.make(task_name, expert_frame_stack, action_repeat, seed, xml_path, episode_len=episode_len)\n",
    "context_changer = context_changers.ReacherHardContextChanger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Expert video recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_video = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    time_step = expert_env.reset()\n",
    "    with utils.change_context(expert_env, context_changer):\n",
    "        source_video.append(expert_env.physics.render(im_w, im_h, camera_id=cam_id))\n",
    "    while not time_step.last():\n",
    "        action = expert.act(time_step.observation, 1, eval_mode=True)\n",
    "        time_step = expert_env.step(action)\n",
    "        with utils.change_context(expert_env, context_changer):\n",
    "            source_video.append(expert_env.physics.render(im_w, im_h, camera_id=cam_id))\n",
    "\n",
    "source_video = np.array(source_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_frames = 6\n",
    "_, axes = plt.subplots(nrows=1, ncols=num_frames, figsize=(30, 5))\n",
    "for i in range(num_frames):\n",
    "    axes[i].imshow(source_video[i*4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the predicted video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_step = expert_env.reset()\n",
    "context_changer.reset()\n",
    "\n",
    "with utils.change_context(expert_env, context_changer):\n",
    "    fobs = expert_env.physics.render(im_w, im_h, camera_id=learner_camera_id).copy().transpose((2, 0, 1))\n",
    "fobs = torch.tensor(fobs, device=utils.device(), dtype=torch.float)\n",
    "expert_video = torch.tensor(source_video.transpose((0, 3, 1, 2)), device=utils.device(), dtype=torch.float)\n",
    "\n",
    "state, frame = context_translator.translate(expert_video, fobs)\n",
    "predicted_video = frame.int().detach().cpu().numpy().transpose((0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=num_frames, figsize=(30, 5))\n",
    "for i in range(num_frames):\n",
    "    axes[i].imshow(predicted_video[i*4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building of the target video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_video = []\n",
    "with torch.no_grad():\n",
    "    with utils.change_context(expert_env, context_changer):\n",
    "        target_video.append(expert_env.physics.render(im_w, im_h, camera_id=cam_id))\n",
    "    while not time_step.last():\n",
    "        action = expert.act(time_step.observation, 1, eval_mode=True)\n",
    "        time_step = expert_env.step(action)\n",
    "        with utils.change_context(expert_env, context_changer):\n",
    "            target_video.append(expert_env.physics.render(im_w, im_h, camera_id=cam_id))\n",
    "\n",
    "target_video = np.array(target_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=num_frames, figsize=(30, 5))\n",
    "for i in range(num_frames):\n",
    "    axes[i].imshow(target_video[i*4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_video = np.zeros( (source_video.shape[0], source_video.shape[1], source_video.shape[2] * 3, source_video.shape[3]))\n",
    "\n",
    "all_video[:, :, 0:64, :] = source_video\n",
    "all_video[:, :, 64:128:, :] = predicted_video\n",
    "all_video[:, :, 128:, :] = target_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the final demo video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The video path is `demo/demo_ct.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imageio.mimwrite('demo/demo_ct.mp4', all_video, format='mp4', fps=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}